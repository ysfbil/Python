{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"091_intro_to_transfer_learning_VGG16.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyPAcrHUOeJoGpz50+XoQWie"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"WI6jON6Bn-6O"},"outputs":[],"source":["\n","# https://youtu.be/LOvrfvtiC8c\n","\n","\n","#\n","\n","#Load the VGG model. For the first time it downloads weights from the Internet.\n","#Stored in Keras/Models directory. (Almost 600MB)\n","#We can include arguments to define whether we want to download full model, \n","#Or part only, include weights, classes, etc. "]},{"cell_type":"markdown","source":["Burada keras kütüphanesinde bulunan eğitilmiş bir sınıflandırıcıyı kullanacağız. Buradaki amaç onbinlerce resim ile eğitilmiş bir veriyi alıp kendi resimlerimizi buna dahil etmektir. Kendi resimlerimiz farklı bile olsa eğitilen resimlerde katmanlar kenar tanıma, çember tanıma gibi farklı işlevler gerçekleştirirler bu sebeple büyük fayda sağlar. feature extraction dediğimiz katmanları kullanmak bizlerin işini kolaylaştırır. \n","Bu örnekte sadece hazır eğitimi nasıl kullanacağımızı öğreneceğiz. Sonraki derste ise kendi verimizde kullanmayı"],"metadata":{"id":"8RsuK5l7oEi3"}},{"cell_type":"code","source":["from keras.applications.vgg16 import VGG16\n","# load the model\n","model = VGG16()\n","model.summary()\n","\n","#Let us load an image to test the pretrained VGG model.\n","#These models are developed on powerful computers so we may as well use them for transfer learning\n","#For VGG16 the images need to be 224x224. \n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oGZBZ_r0o17Z","executionInfo":{"status":"ok","timestamp":1661206784483,"user_tz":-180,"elapsed":8362,"user":{"displayName":"Yusuf Bilgen","userId":"05683862783259875968"}},"outputId":"0ea23df3-3cf8-4b0e-bd8b-cffcd640bf24"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels.h5\n","553467904/553467096 [==============================] - 3s 0us/step\n","553476096/553467096 [==============================] - 3s 0us/step\n","Model: \"vgg16\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," input_1 (InputLayer)        [(None, 224, 224, 3)]     0         \n","                                                                 \n"," block1_conv1 (Conv2D)       (None, 224, 224, 64)      1792      \n","                                                                 \n"," block1_conv2 (Conv2D)       (None, 224, 224, 64)      36928     \n","                                                                 \n"," block1_pool (MaxPooling2D)  (None, 112, 112, 64)      0         \n","                                                                 \n"," block2_conv1 (Conv2D)       (None, 112, 112, 128)     73856     \n","                                                                 \n"," block2_conv2 (Conv2D)       (None, 112, 112, 128)     147584    \n","                                                                 \n"," block2_pool (MaxPooling2D)  (None, 56, 56, 128)       0         \n","                                                                 \n"," block3_conv1 (Conv2D)       (None, 56, 56, 256)       295168    \n","                                                                 \n"," block3_conv2 (Conv2D)       (None, 56, 56, 256)       590080    \n","                                                                 \n"," block3_conv3 (Conv2D)       (None, 56, 56, 256)       590080    \n","                                                                 \n"," block3_pool (MaxPooling2D)  (None, 28, 28, 256)       0         \n","                                                                 \n"," block4_conv1 (Conv2D)       (None, 28, 28, 512)       1180160   \n","                                                                 \n"," block4_conv2 (Conv2D)       (None, 28, 28, 512)       2359808   \n","                                                                 \n"," block4_conv3 (Conv2D)       (None, 28, 28, 512)       2359808   \n","                                                                 \n"," block4_pool (MaxPooling2D)  (None, 14, 14, 512)       0         \n","                                                                 \n"," block5_conv1 (Conv2D)       (None, 14, 14, 512)       2359808   \n","                                                                 \n"," block5_conv2 (Conv2D)       (None, 14, 14, 512)       2359808   \n","                                                                 \n"," block5_conv3 (Conv2D)       (None, 14, 14, 512)       2359808   \n","                                                                 \n"," block5_pool (MaxPooling2D)  (None, 7, 7, 512)         0         \n","                                                                 \n"," flatten (Flatten)           (None, 25088)             0         \n","                                                                 \n"," fc1 (Dense)                 (None, 4096)              102764544 \n","                                                                 \n"," fc2 (Dense)                 (None, 4096)              16781312  \n","                                                                 \n"," predictions (Dense)         (None, 1000)              4097000   \n","                                                                 \n","=================================================================\n","Total params: 138,357,544\n","Trainable params: 138,357,544\n","Non-trainable params: 0\n","_________________________________________________________________\n"]}]},{"cell_type":"code","source":["from keras.preprocessing.image import load_img\n","from keras.preprocessing.image import img_to_array\n","import numpy as np\n","from keras.applications.vgg16 import preprocess_input\n","from tensorflow.keras.applications.mobilenet import decode_predictions"],"metadata":{"id":"yWdZBCnppCCk","executionInfo":{"status":"ok","timestamp":1661206860199,"user_tz":-180,"elapsed":4,"user":{"displayName":"Yusuf Bilgen","userId":"05683862783259875968"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["\n","image = load_img('7.png', target_size=(224, 224))\n","\n","#Convert pixels to Numpy array                                      \n","image = img_to_array(image)\n","\n","# Reshape data for the model. VGG expects multiple images of size 224x224x3, \n","#therefore the input shape needs to be (1, 224, 224, 3)\n","#image = image.reshape((1, image.shape[0], image.shape[1], image.shape[2]))\n","image = np.expand_dims(image, axis=0)\n","\n","#Data needs to be preprocessed same way as the training dataset, to get best results\n","#preprocessing from Keras does this job. \n","#Notice the change in pixel values (Preprocessing subtracts mean RGB value of training set from each pixel)\n","image = preprocess_input(image)\n","\n","\n","# predict the probability across all output categories.\n","#Probability for each of the 1000 classes will be calculated.\n","pred = model.predict(image)\n","\n"],"metadata":{"id":"vxSeCtqbo5N-","executionInfo":{"status":"ok","timestamp":1661207226420,"user_tz":-180,"elapsed":768,"user":{"displayName":"Yusuf Bilgen","userId":"05683862783259875968"}}},"execution_count":16,"outputs":[]},{"cell_type":"code","source":["#Print the probabilities of the top 5 classes\n","pred_classes = decode_predictions(pred, top=5)\n","for i in pred_classes[0]:\n","    print(i)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qapUTKBXpcOv","executionInfo":{"status":"ok","timestamp":1661207227442,"user_tz":-180,"elapsed":3,"user":{"displayName":"Yusuf Bilgen","userId":"05683862783259875968"}},"outputId":"8016bcbb-a35d-443a-a659-62b56c36577c"},"execution_count":17,"outputs":[{"output_type":"stream","name":"stdout","text":["('n02437616', 'llama', 0.79375046)\n","('n02417914', 'ibex', 0.050606534)\n","('n02415577', 'bighorn', 0.02731166)\n","('n02410509', 'bison', 0.026544962)\n","('n02412080', 'ram', 0.020558124)\n"]}]},{"cell_type":"code","source":[""],"metadata":{"id":"bn1YCcCGpt3I"},"execution_count":null,"outputs":[]}]}