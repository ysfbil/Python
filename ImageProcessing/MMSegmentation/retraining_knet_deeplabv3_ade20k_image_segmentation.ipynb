{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":77569,"status":"ok","timestamp":1660654333562,"user":{"displayName":"Yusuf Bilgen","userId":"05683862783259875968"},"user_tz":-180},"id":"k_QBTxgK78hN","outputId":"51533c86-c301-4487-c75c-d5c6cf990bcd"},"outputs":[{"name":"stdout","output_type":"stream","text":["--2022-08-16 12:50:54--  http://data.csail.mit.edu/places/ADEchallenge/ADEChallengeData2016.zip\n","Resolving data.csail.mit.edu (data.csail.mit.edu)... 128.52.129.40\n","Connecting to data.csail.mit.edu (data.csail.mit.edu)|128.52.129.40|:80... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 967382037 (923M) [application/zip]\n","Saving to: ‘ade20k/ADEChallengeData2016.zip’\n","\n","ADEChallengeData201 100%[===================\u003e] 922.57M  12.6MB/s    in 77s     \n","\n","2022-08-16 12:52:12 (12.0 MB/s) - ‘ade20k/ADEChallengeData2016.zip’ saved [967382037/967382037]\n","\n"]}],"source":["!mkdir ade20k\n","!wget http://data.csail.mit.edu/places/ADEchallenge/ADEChallengeData2016.zip -P ade20k"]},{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":17,"status":"ok","timestamp":1660654333563,"user":{"displayName":"Yusuf Bilgen","userId":"05683862783259875968"},"user_tz":-180},"id":"oB0t3UmsNKUj"},"outputs":[],"source":["#!wget http://data.csail.mit.edu/places/ADEchallenge/release_test.zip -P ade20k"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7856,"status":"ok","timestamp":1660654341413,"user":{"displayName":"Yusuf Bilgen","userId":"05683862783259875968"},"user_tz":-180},"id":"pQnJj626i_dh","outputId":"cad7418e-41db-48c3-b10b-885a0af1d647"},"outputs":[{"name":"stdout","output_type":"stream","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting openmim\n","  Downloading openmim-0.2.1-py2.py3-none-any.whl (49 kB)\n","\u001b[K     |████████████████████████████████| 49 kB 5.5 MB/s \n","\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from openmim) (1.3.5)\n","Requirement already satisfied: pip\u003e=19.3 in /usr/local/lib/python3.7/dist-packages (from openmim) (21.1.3)\n","Collecting model-index\n","  Downloading model_index-0.1.11-py3-none-any.whl (34 kB)\n","Requirement already satisfied: Click in /usr/local/lib/python3.7/dist-packages (from openmim) (7.1.2)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from openmim) (2.23.0)\n","Collecting rich\n","  Downloading rich-12.5.1-py3-none-any.whl (235 kB)\n","\u001b[K     |████████████████████████████████| 235 kB 60.4 MB/s \n","\u001b[?25hCollecting colorama\n","  Downloading colorama-0.4.5-py2.py3-none-any.whl (16 kB)\n","Requirement already satisfied: tabulate in /usr/local/lib/python3.7/dist-packages (from openmim) (0.8.10)\n","Collecting ordered-set\n","  Downloading ordered_set-4.1.0-py3-none-any.whl (7.6 kB)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from model-index-\u003eopenmim) (3.13)\n","Requirement already satisfied: markdown in /usr/local/lib/python3.7/dist-packages (from model-index-\u003eopenmim) (3.4.1)\n","Requirement already satisfied: importlib-metadata\u003e=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown-\u003emodel-index-\u003eopenmim) (4.12.0)\n","Requirement already satisfied: zipp\u003e=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata\u003e=4.4-\u003emarkdown-\u003emodel-index-\u003eopenmim) (3.8.1)\n","Requirement already satisfied: typing-extensions\u003e=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata\u003e=4.4-\u003emarkdown-\u003emodel-index-\u003eopenmim) (4.1.1)\n","Requirement already satisfied: numpy\u003e=1.17.3 in /usr/local/lib/python3.7/dist-packages (from pandas-\u003eopenmim) (1.21.6)\n","Requirement already satisfied: pytz\u003e=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas-\u003eopenmim) (2022.1)\n","Requirement already satisfied: python-dateutil\u003e=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas-\u003eopenmim) (2.8.2)\n","Requirement already satisfied: six\u003e=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil\u003e=2.7.3-\u003epandas-\u003eopenmim) (1.15.0)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,\u003c1.26,\u003e=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests-\u003eopenmim) (1.24.3)\n","Requirement already satisfied: idna\u003c3,\u003e=2.5 in /usr/local/lib/python3.7/dist-packages (from requests-\u003eopenmim) (2.10)\n","Requirement already satisfied: chardet\u003c4,\u003e=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests-\u003eopenmim) (3.0.4)\n","Requirement already satisfied: certifi\u003e=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests-\u003eopenmim) (2022.6.15)\n","Collecting commonmark\u003c0.10.0,\u003e=0.9.0\n","  Downloading commonmark-0.9.1-py2.py3-none-any.whl (51 kB)\n","\u001b[K     |████████████████████████████████| 51 kB 8.3 MB/s \n","\u001b[?25hRequirement already satisfied: pygments\u003c3.0.0,\u003e=2.6.0 in /usr/local/lib/python3.7/dist-packages (from rich-\u003eopenmim) (2.6.1)\n","Installing collected packages: ordered-set, commonmark, rich, model-index, colorama, openmim\n","Successfully installed colorama-0.4.5 commonmark-0.9.1 model-index-0.1.11 openmim-0.2.1 ordered-set-4.1.0 rich-12.5.1\n"]}],"source":["!pip3 install openmim"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":14277,"status":"ok","timestamp":1660654355679,"user":{"displayName":"Yusuf Bilgen","userId":"05683862783259875968"},"user_tz":-180},"id":"0SZGk9F6jFbR","outputId":"4ec62488-f8ce-4565-d938-18e00828d1e3"},"outputs":[{"name":"stdout","output_type":"stream","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Looking in links: https://download.openmmlab.com/mmcv/dist/cu113/torch1.12.0/index.html\n","Collecting mmcv-full\n","  Downloading https://download.openmmlab.com/mmcv/dist/cu113/torch1.12.0/mmcv_full-1.6.1-cp37-cp37m-manylinux1_x86_64.whl (40.6 MB)\n","\u001b[K     |████████████████████████████████| 40.6 MB 1.4 MB/s \n","\u001b[?25hRequirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from mmcv-full) (3.13)\n","Collecting addict\n","  Downloading addict-2.4.0-py3-none-any.whl (3.8 kB)\n","Requirement already satisfied: opencv-python\u003e=3 in /usr/local/lib/python3.7/dist-packages (from mmcv-full) (4.6.0.66)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from mmcv-full) (21.3)\n","Requirement already satisfied: Pillow in /usr/local/lib/python3.7/dist-packages (from mmcv-full) (7.1.2)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from mmcv-full) (1.21.6)\n","Collecting yapf\n","  Downloading yapf-0.32.0-py2.py3-none-any.whl (190 kB)\n","\u001b[K     |████████████████████████████████| 190 kB 18.3 MB/s \n","\u001b[?25hRequirement already satisfied: pyparsing!=3.0.5,\u003e=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging-\u003emmcv-full) (3.0.9)\n","Installing collected packages: yapf, addict, mmcv-full\n","Successfully installed addict-2.4.0 mmcv-full-1.6.1 yapf-0.32.0\n"]}],"source":["!mim install mmcv-full"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":14937,"status":"ok","timestamp":1660654370598,"user":{"displayName":"Yusuf Bilgen","userId":"05683862783259875968"},"user_tz":-180},"id":"p1cnAULQjN7F","outputId":"c963ee90-88db-4daf-d378-0c3c4dc986eb"},"outputs":[{"name":"stdout","output_type":"stream","text":["Cloning into 'mmsegmentation'...\n","remote: Enumerating objects: 10481, done.\u001b[K\n","remote: Counting objects: 100% (356/356), done.\u001b[K\n","remote: Compressing objects: 100% (224/224), done.\u001b[K\n","remote: Total 10481 (delta 160), reused 290 (delta 130), pack-reused 10125\u001b[K\n","Receiving objects: 100% (10481/10481), 14.60 MiB | 4.33 MiB/s, done.\n","Resolving deltas: 100% (7590/7590), done.\n","/content/mmsegmentation\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Obtaining file:///content/mmsegmentation\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from mmsegmentation==0.27.0) (3.2.2)\n","Collecting mmcls\u003e=0.20.1\n","  Downloading mmcls-0.23.2-py2.py3-none-any.whl (578 kB)\n","\u001b[K     |████████████████████████████████| 578 kB 20.8 MB/s \n","\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from mmsegmentation==0.27.0) (1.21.6)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from mmsegmentation==0.27.0) (21.3)\n","Requirement already satisfied: prettytable in /usr/local/lib/python3.7/dist-packages (from mmsegmentation==0.27.0) (3.3.0)\n","Requirement already satisfied: kiwisolver\u003e=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib-\u003emmsegmentation==0.27.0) (1.4.4)\n","Requirement already satisfied: python-dateutil\u003e=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib-\u003emmsegmentation==0.27.0) (2.8.2)\n","Requirement already satisfied: cycler\u003e=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib-\u003emmsegmentation==0.27.0) (0.11.0)\n","Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,\u003e=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib-\u003emmsegmentation==0.27.0) (3.0.9)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from kiwisolver\u003e=1.0.1-\u003ematplotlib-\u003emmsegmentation==0.27.0) (4.1.1)\n","Requirement already satisfied: six\u003e=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil\u003e=2.1-\u003ematplotlib-\u003emmsegmentation==0.27.0) (1.15.0)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from prettytable-\u003emmsegmentation==0.27.0) (4.12.0)\n","Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prettytable-\u003emmsegmentation==0.27.0) (0.2.5)\n","Requirement already satisfied: zipp\u003e=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata-\u003eprettytable-\u003emmsegmentation==0.27.0) (3.8.1)\n","Installing collected packages: mmcls, mmsegmentation\n","  Running setup.py develop for mmsegmentation\n","Successfully installed mmcls-0.23.2 mmsegmentation-0.27.0\n"]}],"source":["!git clone https://github.com/open-mmlab/mmsegmentation.git\n","%cd mmsegmentation\n","!pip install -e ."]},{"cell_type":"code","execution_count":6,"metadata":{"executionInfo":{"elapsed":629,"status":"ok","timestamp":1660654371212,"user":{"displayName":"Yusuf Bilgen","userId":"05683862783259875968"},"user_tz":-180},"id":"10d-4QHoQswW"},"outputs":[],"source":["!mkdir /content/mmsegmentation/data\n","!mkdir /content/mmsegmentation/data/ade"]},{"cell_type":"code","execution_count":7,"metadata":{"executionInfo":{"elapsed":14436,"status":"ok","timestamp":1660654385645,"user":{"displayName":"Yusuf Bilgen","userId":"05683862783259875968"},"user_tz":-180},"id":"yLf5EhQeQu1G"},"outputs":[],"source":["!unzip -q /content/ade20k/ADEChallengeData2016.zip -d /content/mmsegmentation/data/ade"]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3795,"status":"ok","timestamp":1660654389425,"user":{"displayName":"Yusuf Bilgen","userId":"05683862783259875968"},"user_tz":-180},"id":"XvePCpD7jQ96","outputId":"1dd3bb5d-7420-4002-b0d2-75c3ad6b683e"},"outputs":[{"name":"stdout","output_type":"stream","text":["1.12.1+cu113 True\n","0.27.0\n"]}],"source":["# Check Pytorch installation\n","import torch, torchvision\n","print(torch.__version__, torch.cuda.is_available())\n","\n","# Check MMSegmentation installation\n","import mmseg\n","print(mmseg.__version__)"]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":25553,"status":"ok","timestamp":1660654414961,"user":{"displayName":"Yusuf Bilgen","userId":"05683862783259875968"},"user_tz":-180},"id":"0hcZIJDgjbyM","outputId":"ca0a76f4-cb83-409c-89ee-11b6f4233735"},"outputs":[{"name":"stdout","output_type":"stream","text":["--2022-08-16 12:53:08--  https://download.openmmlab.com/mmsegmentation/v0.5/knet/knet_s3_deeplabv3_r50-d8_8x2_512x512_adamw_80k_ade20k/knet_s3_deeplabv3_r50-d8_8x2_512x512_adamw_80k_ade20k_20220228_041642-00c8fbeb.pth\n","Resolving download.openmmlab.com (download.openmmlab.com)... 161.117.242.73\n","Connecting to download.openmmlab.com (download.openmmlab.com)|161.117.242.73|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 326152452 (311M) [application/octet-stream]\n","Saving to: ‘checkpoints/knet_s3_deeplabv3_r50-d8_8x2_512x512_adamw_80k_ade20k_20220228_041642-00c8fbeb.pth’\n","\n","knet_s3_deeplabv3_r 100%[===================\u003e] 311.04M  11.4MB/s    in 24s     \n","\n","2022-08-16 12:53:33 (12.9 MB/s) - ‘checkpoints/knet_s3_deeplabv3_r50-d8_8x2_512x512_adamw_80k_ade20k_20220228_041642-00c8fbeb.pth’ saved [326152452/326152452]\n","\n"]}],"source":["!mkdir checkpoints\n","#!wget https://download.openmmlab.com/mmsegmentation/v0.5/knet/knet_s3_fcn_r50-d8_8x2_512x512_adamw_80k_ade20k/knet_s3_fcn_r50-d8_8x2_512x512_adamw_80k_ade20k_20220228_043751-abcab920.pth -P checkpoints\n","!wget https://download.openmmlab.com/mmsegmentation/v0.5/knet/knet_s3_deeplabv3_r50-d8_8x2_512x512_adamw_80k_ade20k/knet_s3_deeplabv3_r50-d8_8x2_512x512_adamw_80k_ade20k_20220228_041642-00c8fbeb.pth -P checkpoints"]},{"cell_type":"code","execution_count":10,"metadata":{"executionInfo":{"elapsed":754,"status":"ok","timestamp":1660654415700,"user":{"displayName":"Yusuf Bilgen","userId":"05683862783259875968"},"user_tz":-180},"id":"_yFQigsSlba2"},"outputs":[],"source":["from mmseg.apis import inference_segmentor, init_segmentor, show_result_pyplot\n","from mmseg.core.evaluation import get_palette"]},{"cell_type":"code","execution_count":12,"metadata":{"executionInfo":{"elapsed":469,"status":"ok","timestamp":1660654477688,"user":{"displayName":"Yusuf Bilgen","userId":"05683862783259875968"},"user_tz":-180},"id":"8o-98ZEkmBgq"},"outputs":[],"source":["\n","from mmcv import Config\n","\n","#config_file = '/content/mmsegmentation/configs/knet/knet_s3_deeplabv3_r50-d8_8x2_512x512_adamw_80k_ade20k.py'\n","\n","#yukarıdakini yükleyip aşağıdaki gibi kod ile düzenleyince hata aldım ve düzeltemedim. Dosyanın kendisinden aynı değişiklikleri \n","#yapıp çalıştırınca oldu.\n","config_file='/content/mmsegmentation/configs/knet/knet_deep_test.py'\n","#'configs/knet/knet_s3_fcn_r50-d8_8x2_512x512_adamw_80k_ade20k.py'\n","checkpoint_file = 'checkpoints/knet_s3_deeplabv3_r50-d8_8x2_512x512_adamw_80k_ade20k_20220228_041642-00c8fbeb.pth'\n","#'checkpoints/knet_s3_fcn_r50-d8_8x2_512x512_adamw_80k_ade20k_20220228_043751-abcab920.pth'\n","cfg = Config.fromfile(config_file)\n"]},{"cell_type":"code","execution_count":14,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":140},"executionInfo":{"elapsed":483,"status":"ok","timestamp":1660654498346,"user":{"displayName":"Yusuf Bilgen","userId":"05683862783259875968"},"user_tz":-180},"id":"m2iGM7ywhkRR","outputId":"83b2df16-ed8f-4373-ff44-e41d084aa910"},"outputs":[{"data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["\"\\nfrom mmseg.apis import set_random_seed\\nfrom mmseg.utils import get_device\\n\\n\\n# Since we use only one GPU, BN is used instead of SyncBN\\ncfg.norm_cfg = dict(type='BN', requires_grad=True)\\ncfg.model.backbone.norm_cfg = cfg.norm_cfg\\ncfg.model.auxiliary_head.norm_cfg = cfg.norm_cfg\\n\\ncfg.runner.max_iters = 200\\ncfg.log_config.interval = 10\\ncfg.evaluation.interval = 200\\ncfg.checkpoint_config.interval = 200\\n\\n# We can still use the pre-trained Mask RCNN model though we do not need to\\n# use the mask branch\\ncfg.load_from = checkpoint_file\\n\\n# Set up working dir to save files and logs.\\ncfg.work_dir = './work_dirs/tutorial'\\n\\n\\n\\n# Set seed to facitate reproducing the result\\ncfg.seed = 0\\nset_random_seed(0, deterministic=False)\\ncfg.gpu_ids = range(1)\\ncfg.device = get_device()\\n\\n\""]},"execution_count":14,"metadata":{},"output_type":"execute_result"}],"source":["'''\n","from mmseg.apis import set_random_seed\n","from mmseg.utils import get_device\n","\n","\n","# Since we use only one GPU, BN is used instead of SyncBN\n","cfg.norm_cfg = dict(type='BN', requires_grad=True)\n","cfg.model.backbone.norm_cfg = cfg.norm_cfg\n","cfg.model.auxiliary_head.norm_cfg = cfg.norm_cfg\n","\n","cfg.runner.max_iters = 200\n","cfg.log_config.interval = 10\n","cfg.evaluation.interval = 200\n","cfg.checkpoint_config.interval = 200\n","\n","# We can still use the pre-trained Mask RCNN model though we do not need to\n","# use the mask branch\n","cfg.load_from = checkpoint_file\n","\n","# Set up working dir to save files and logs.\n","cfg.work_dir = './work_dirs/tutorial'\n","\n","\n","\n","# Set seed to facitate reproducing the result\n","cfg.seed = 0\n","set_random_seed(0, deterministic=False)\n","cfg.gpu_ids = range(1)\n","cfg.device = get_device()\n","\n","'''"]},{"cell_type":"code","execution_count":15,"metadata":{"executionInfo":{"elapsed":6,"status":"ok","timestamp":1660654499520,"user":{"displayName":"Yusuf Bilgen","userId":"05683862783259875968"},"user_tz":-180},"id":"-Dw-wZpxQmPI"},"outputs":[],"source":["from mmseg.apis import set_random_seed\n","from mmseg.utils import get_device\n","\n","cfg.load_from = checkpoint_file\n","cfg.work_dir = './work_dirs/tutorial'\n","cfg.seed = 0\n","set_random_seed(0, deterministic=False)\n","cfg.gpu_ids = range(1)\n","cfg.device = get_device()\n"]},{"cell_type":"code","execution_count":16,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":673,"status":"ok","timestamp":1660654500188,"user":{"displayName":"Yusuf Bilgen","userId":"05683862783259875968"},"user_tz":-180},"id":"dzRkXHQvLbiB","outputId":"04212935-d803-422d-f8a8-89c9217efbe6"},"outputs":[{"name":"stdout","output_type":"stream","text":["Config:\n","dataset_type = 'ADE20KDataset'\n","data_root = 'data/ade/ADEChallengeData2016'\n","img_norm_cfg = dict(\n","    mean=[123.675, 116.28, 103.53], std=[58.395, 57.12, 57.375], to_rgb=True)\n","crop_size = (512, 512)\n","train_pipeline = [\n","    dict(type='LoadImageFromFile'),\n","    dict(type='LoadAnnotations', reduce_zero_label=True),\n","    dict(type='Resize', img_scale=(2048, 512), ratio_range=(0.5, 2.0)),\n","    dict(type='RandomCrop', crop_size=(512, 512), cat_max_ratio=0.75),\n","    dict(type='RandomFlip', prob=0.5),\n","    dict(type='PhotoMetricDistortion'),\n","    dict(\n","        type='Normalize',\n","        mean=[123.675, 116.28, 103.53],\n","        std=[58.395, 57.12, 57.375],\n","        to_rgb=True),\n","    dict(type='Pad', size=(512, 512), pad_val=0, seg_pad_val=255),\n","    dict(type='DefaultFormatBundle'),\n","    dict(type='Collect', keys=['img', 'gt_semantic_seg'])\n","]\n","test_pipeline = [\n","    dict(type='LoadImageFromFile'),\n","    dict(\n","        type='MultiScaleFlipAug',\n","        img_scale=(2048, 512),\n","        flip=False,\n","        transforms=[\n","            dict(type='Resize', keep_ratio=True),\n","            dict(type='RandomFlip'),\n","            dict(\n","                type='Normalize',\n","                mean=[123.675, 116.28, 103.53],\n","                std=[58.395, 57.12, 57.375],\n","                to_rgb=True),\n","            dict(type='ImageToTensor', keys=['img']),\n","            dict(type='Collect', keys=['img'])\n","        ])\n","]\n","data = dict(\n","    samples_per_gpu=2,\n","    workers_per_gpu=2,\n","    train=dict(\n","        type='ADE20KDataset',\n","        data_root='data/ade/ADEChallengeData2016',\n","        img_dir='images/training',\n","        ann_dir='annotations/training',\n","        pipeline=[\n","            dict(type='LoadImageFromFile'),\n","            dict(type='LoadAnnotations', reduce_zero_label=True),\n","            dict(type='Resize', img_scale=(2048, 512), ratio_range=(0.5, 2.0)),\n","            dict(type='RandomCrop', crop_size=(512, 512), cat_max_ratio=0.75),\n","            dict(type='RandomFlip', prob=0.5),\n","            dict(type='PhotoMetricDistortion'),\n","            dict(\n","                type='Normalize',\n","                mean=[123.675, 116.28, 103.53],\n","                std=[58.395, 57.12, 57.375],\n","                to_rgb=True),\n","            dict(type='Pad', size=(512, 512), pad_val=0, seg_pad_val=255),\n","            dict(type='DefaultFormatBundle'),\n","            dict(type='Collect', keys=['img', 'gt_semantic_seg'])\n","        ]),\n","    val=dict(\n","        type='ADE20KDataset',\n","        data_root='data/ade/ADEChallengeData2016',\n","        img_dir='images/validation',\n","        ann_dir='annotations/validation',\n","        pipeline=[\n","            dict(type='LoadImageFromFile'),\n","            dict(\n","                type='MultiScaleFlipAug',\n","                img_scale=(2048, 512),\n","                flip=False,\n","                transforms=[\n","                    dict(type='Resize', keep_ratio=True),\n","                    dict(type='RandomFlip'),\n","                    dict(\n","                        type='Normalize',\n","                        mean=[123.675, 116.28, 103.53],\n","                        std=[58.395, 57.12, 57.375],\n","                        to_rgb=True),\n","                    dict(type='ImageToTensor', keys=['img']),\n","                    dict(type='Collect', keys=['img'])\n","                ])\n","        ]),\n","    test=dict(\n","        type='ADE20KDataset',\n","        data_root='data/ade/ADEChallengeData2016',\n","        img_dir='images/validation',\n","        ann_dir='annotations/validation',\n","        pipeline=[\n","            dict(type='LoadImageFromFile'),\n","            dict(\n","                type='MultiScaleFlipAug',\n","                img_scale=(2048, 512),\n","                flip=False,\n","                transforms=[\n","                    dict(type='Resize', keep_ratio=True),\n","                    dict(type='RandomFlip'),\n","                    dict(\n","                        type='Normalize',\n","                        mean=[123.675, 116.28, 103.53],\n","                        std=[58.395, 57.12, 57.375],\n","                        to_rgb=True),\n","                    dict(type='ImageToTensor', keys=['img']),\n","                    dict(type='Collect', keys=['img'])\n","                ])\n","        ]))\n","log_config = dict(\n","    interval=50, hooks=[dict(type='TextLoggerHook', by_epoch=False)])\n","dist_params = dict(backend='nccl')\n","log_level = 'INFO'\n","load_from = 'checkpoints/knet_s3_deeplabv3_r50-d8_8x2_512x512_adamw_80k_ade20k_20220228_041642-00c8fbeb.pth'\n","resume_from = None\n","workflow = [('train', 1)]\n","cudnn_benchmark = True\n","optimizer = dict(type='AdamW', lr=0.0001, weight_decay=0.0005)\n","optimizer_config = dict(grad_clip=dict(max_norm=1, norm_type=2))\n","lr_config = dict(\n","    policy='step',\n","    warmup='linear',\n","    warmup_iters=1000,\n","    warmup_ratio=0.001,\n","    step=[60000, 72000],\n","    by_epoch=False)\n","runner = dict(type='IterBasedRunner', max_iters=200)\n","checkpoint_config = dict(by_epoch=False, interval=200)\n","evaluation = dict(interval=200, metric='mIoU', pre_eval=True)\n","norm_cfg = dict(type='BN', requires_grad=True)\n","num_stages = 3\n","conv_kernel_size = 1\n","model = dict(\n","    type='EncoderDecoder',\n","    pretrained='open-mmlab://resnet50_v1c',\n","    backbone=dict(\n","        type='ResNetV1c',\n","        depth=50,\n","        num_stages=4,\n","        out_indices=(0, 1, 2, 3),\n","        dilations=(1, 1, 2, 4),\n","        strides=(1, 2, 1, 1),\n","        norm_cfg=dict(type='BN', requires_grad=True),\n","        norm_eval=False,\n","        style='pytorch',\n","        contract_dilation=True),\n","    decode_head=dict(\n","        type='IterativeDecodeHead',\n","        num_stages=3,\n","        kernel_update_head=[\n","            dict(\n","                type='KernelUpdateHead',\n","                num_classes=150,\n","                num_ffn_fcs=2,\n","                num_heads=8,\n","                num_mask_fcs=1,\n","                feedforward_channels=2048,\n","                in_channels=512,\n","                out_channels=512,\n","                dropout=0.0,\n","                conv_kernel_size=1,\n","                ffn_act_cfg=dict(type='ReLU', inplace=True),\n","                with_ffn=True,\n","                feat_transform_cfg=dict(\n","                    conv_cfg=dict(type='Conv2d'), act_cfg=None),\n","                kernel_updator_cfg=dict(\n","                    type='KernelUpdator',\n","                    in_channels=256,\n","                    feat_channels=256,\n","                    out_channels=256,\n","                    act_cfg=dict(type='ReLU', inplace=True),\n","                    norm_cfg=dict(type='LN'))),\n","            dict(\n","                type='KernelUpdateHead',\n","                num_classes=150,\n","                num_ffn_fcs=2,\n","                num_heads=8,\n","                num_mask_fcs=1,\n","                feedforward_channels=2048,\n","                in_channels=512,\n","                out_channels=512,\n","                dropout=0.0,\n","                conv_kernel_size=1,\n","                ffn_act_cfg=dict(type='ReLU', inplace=True),\n","                with_ffn=True,\n","                feat_transform_cfg=dict(\n","                    conv_cfg=dict(type='Conv2d'), act_cfg=None),\n","                kernel_updator_cfg=dict(\n","                    type='KernelUpdator',\n","                    in_channels=256,\n","                    feat_channels=256,\n","                    out_channels=256,\n","                    act_cfg=dict(type='ReLU', inplace=True),\n","                    norm_cfg=dict(type='LN'))),\n","            dict(\n","                type='KernelUpdateHead',\n","                num_classes=150,\n","                num_ffn_fcs=2,\n","                num_heads=8,\n","                num_mask_fcs=1,\n","                feedforward_channels=2048,\n","                in_channels=512,\n","                out_channels=512,\n","                dropout=0.0,\n","                conv_kernel_size=1,\n","                ffn_act_cfg=dict(type='ReLU', inplace=True),\n","                with_ffn=True,\n","                feat_transform_cfg=dict(\n","                    conv_cfg=dict(type='Conv2d'), act_cfg=None),\n","                kernel_updator_cfg=dict(\n","                    type='KernelUpdator',\n","                    in_channels=256,\n","                    feat_channels=256,\n","                    out_channels=256,\n","                    act_cfg=dict(type='ReLU', inplace=True),\n","                    norm_cfg=dict(type='LN')))\n","        ],\n","        kernel_generate_head=dict(\n","            type='ASPPHead',\n","            in_channels=2048,\n","            in_index=3,\n","            channels=512,\n","            dilations=(1, 12, 24, 36),\n","            dropout_ratio=0.1,\n","            num_classes=150,\n","            norm_cfg=dict(type='BN', requires_grad=True),\n","            align_corners=False,\n","            loss_decode=dict(\n","                type='CrossEntropyLoss', use_sigmoid=False, loss_weight=1.0))),\n","    auxiliary_head=dict(\n","        type='FCNHead',\n","        in_channels=1024,\n","        in_index=2,\n","        channels=256,\n","        num_convs=1,\n","        concat_input=False,\n","        dropout_ratio=0.1,\n","        num_classes=150,\n","        norm_cfg=dict(type='BN', requires_grad=True),\n","        align_corners=False,\n","        loss_decode=dict(\n","            type='CrossEntropyLoss', use_sigmoid=False, loss_weight=0.4)),\n","    train_cfg=dict(),\n","    test_cfg=dict(mode='whole'))\n","work_dir = './work_dirs/tutorial'\n","seed = 0\n","gpu_ids = range(0, 1)\n","device = 'cuda'\n","\n"]}],"source":["# Let's have a look at the final config used for training\n","print(f'Config:\\n{cfg.pretty_text}')"]},{"cell_type":"code","execution_count":17,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":832029,"status":"ok","timestamp":1660655332205,"user":{"displayName":"Yusuf Bilgen","userId":"05683862783259875968"},"user_tz":-180},"id":"toMRFL6gnPdG","outputId":"e79fd663-d0a8-4f9a-cdfb-9467e5358e28"},"outputs":[{"name":"stderr","output_type":"stream","text":["2022-08-16 12:54:58,533 - mmseg - INFO - Loaded 20210 images\n","/content/mmsegmentation/mmseg/models/backbones/resnet.py:431: UserWarning: DeprecationWarning: pretrained is a deprecated, please use \"init_cfg\" instead\n","  warnings.warn('DeprecationWarning: pretrained is a deprecated, '\n","/content/mmsegmentation/mmseg/models/losses/cross_entropy_loss.py:236: UserWarning: Default ``avg_non_ignore`` is False, if you would like to ignore the certain label and average loss over non-ignore labels, which is the same with PyTorch official cross_entropy, set ``avg_non_ignore=True``.\n","  'Default ``avg_non_ignore`` is False, if you would like to '\n","2022-08-16 12:55:03,600 - mmseg - INFO - Loaded 2000 images\n","2022-08-16 12:55:03,602 - mmseg - INFO - load checkpoint from local path: checkpoints/knet_s3_deeplabv3_r50-d8_8x2_512x512_adamw_80k_ade20k_20220228_041642-00c8fbeb.pth\n","2022-08-16 12:55:03,864 - mmseg - INFO - Start running, host: root@f1632e44cb68, work_dir: /content/mmsegmentation/work_dirs/tutorial\n","2022-08-16 12:55:03,866 - mmseg - INFO - Hooks will be executed in the following order:\n","before_run:\n","(VERY_HIGH   ) StepLrUpdaterHook                  \n","(NORMAL      ) CheckpointHook                     \n","(LOW         ) EvalHook                           \n","(VERY_LOW    ) TextLoggerHook                     \n"," -------------------- \n","before_train_epoch:\n","(VERY_HIGH   ) StepLrUpdaterHook                  \n","(LOW         ) IterTimerHook                      \n","(LOW         ) EvalHook                           \n","(VERY_LOW    ) TextLoggerHook                     \n"," -------------------- \n","before_train_iter:\n","(VERY_HIGH   ) StepLrUpdaterHook                  \n","(LOW         ) IterTimerHook                      \n","(LOW         ) EvalHook                           \n"," -------------------- \n","after_train_iter:\n","(ABOVE_NORMAL) OptimizerHook                      \n","(NORMAL      ) CheckpointHook                     \n","(LOW         ) IterTimerHook                      \n","(LOW         ) EvalHook                           \n","(VERY_LOW    ) TextLoggerHook                     \n"," -------------------- \n","after_train_epoch:\n","(NORMAL      ) CheckpointHook                     \n","(LOW         ) EvalHook                           \n","(VERY_LOW    ) TextLoggerHook                     \n"," -------------------- \n","before_val_epoch:\n","(LOW         ) IterTimerHook                      \n","(VERY_LOW    ) TextLoggerHook                     \n"," -------------------- \n","before_val_iter:\n","(LOW         ) IterTimerHook                      \n"," -------------------- \n","after_val_iter:\n","(LOW         ) IterTimerHook                      \n"," -------------------- \n","after_val_epoch:\n","(VERY_LOW    ) TextLoggerHook                     \n"," -------------------- \n","after_run:\n","(VERY_LOW    ) TextLoggerHook                     \n"," -------------------- \n","2022-08-16 12:55:03,871 - mmseg - INFO - workflow: [('train', 1)], max: 200 iters\n","2022-08-16 12:55:03,873 - mmseg - INFO - Checkpoints will be saved to /content/mmsegmentation/work_dirs/tutorial by HardDiskBackend.\n","2022-08-16 12:56:32,508 - mmseg - INFO - Iter [50/200]\tlr: 4.995e-06, eta: 0:04:25, time: 1.771, data_time: 0.008, memory: 5715, decode.loss_ce.s0: 0.8424, decode.acc_seg.s0: 71.6009, decode.loss_ce.s1: 0.5606, decode.acc_seg.s1: 81.0874, decode.loss_ce.s2: 0.5601, decode.acc_seg.s2: 81.1149, decode.loss_ce.s3: 0.5576, decode.acc_seg.s3: 81.0720, aux.loss_ce: 0.6016, aux.acc_seg: 56.0603, loss: 3.1223, grad_norm: 98.1935\n","2022-08-16 12:57:59,056 - mmseg - INFO - Iter [100/200]\tlr: 9.990e-06, eta: 0:02:55, time: 1.731, data_time: 0.003, memory: 5715, decode.loss_ce.s0: 1.0643, decode.acc_seg.s0: 67.9357, decode.loss_ce.s1: 0.7699, decode.acc_seg.s1: 78.1270, decode.loss_ce.s2: 0.7870, decode.acc_seg.s2: 78.2152, decode.loss_ce.s3: 0.7743, decode.acc_seg.s3: 78.2321, aux.loss_ce: 0.7009, aux.acc_seg: 51.4222, loss: 4.0965, grad_norm: 102.6780\n","2022-08-16 12:59:26,304 - mmseg - INFO - Iter [150/200]\tlr: 1.499e-05, eta: 0:01:27, time: 1.745, data_time: 0.005, memory: 5715, decode.loss_ce.s0: 1.0372, decode.acc_seg.s0: 68.5623, decode.loss_ce.s1: 0.6953, decode.acc_seg.s1: 79.0249, decode.loss_ce.s2: 0.6822, decode.acc_seg.s2: 79.6332, decode.loss_ce.s3: 0.6656, decode.acc_seg.s3: 79.6528, aux.loss_ce: 0.6995, aux.acc_seg: 51.8112, loss: 3.7799, grad_norm: 133.4856\n","2022-08-16 13:00:53,383 - mmseg - INFO - Saving checkpoint at 200 iterations\n","2022-08-16 13:01:00,290 - mmseg - INFO - Iter [200/200]\tlr: 1.998e-05, eta: 0:00:00, time: 1.880, data_time: 0.003, memory: 5715, decode.loss_ce.s0: 1.1979, decode.acc_seg.s0: 64.4836, decode.loss_ce.s1: 0.8038, decode.acc_seg.s1: 76.9723, decode.loss_ce.s2: 0.7934, decode.acc_seg.s2: 77.3681, decode.loss_ce.s3: 0.7728, decode.acc_seg.s3: 77.4422, aux.loss_ce: 0.8283, aux.acc_seg: 46.9208, loss: 4.3963, grad_norm: 166.9864\n"]},{"name":"stdout","output_type":"stream","text":["[\u003e\u003e\u003e\u003e\u003e\u003e\u003e\u003e\u003e\u003e\u003e\u003e\u003e\u003e\u003e\u003e\u003e\u003e\u003e\u003e\u003e\u003e\u003e\u003e\u003e\u003e\u003e] 2000/2000, 4.3 task/s, elapsed: 467s, ETA:     0s"]},{"name":"stderr","output_type":"stream","text":["2022-08-16 13:08:47,498 - mmseg - INFO - per class results:\n","2022-08-16 13:08:47,509 - mmseg - INFO - \n","+---------------------+-------+-------+\n","|        Class        |  IoU  |  Acc  |\n","+---------------------+-------+-------+\n","|         wall        | 73.82 | 87.08 |\n","|       building      | 79.12 | 91.29 |\n","|         sky         | 92.49 | 95.82 |\n","|        floor        | 77.02 | 87.46 |\n","|         tree        | 70.45 |  85.9 |\n","|       ceiling       | 79.77 | 89.16 |\n","|         road        | 79.52 | 86.49 |\n","|         bed         | 83.62 | 96.09 |\n","|      windowpane     | 56.68 | 70.37 |\n","|        grass        | 60.13 | 80.95 |\n","|       cabinet       | 54.65 | 67.93 |\n","|       sidewalk      | 61.09 | 75.09 |\n","|        person       | 76.15 | 87.52 |\n","|        earth        |  27.2 | 37.65 |\n","|         door        | 44.51 | 59.13 |\n","|        table        |  54.3 | 69.59 |\n","|       mountain      | 46.54 |  62.5 |\n","|        plant        | 51.12 | 64.11 |\n","|       curtain       | 64.33 | 80.75 |\n","|        chair        | 51.59 | 65.97 |\n","|         car         | 80.16 | 87.79 |\n","|        water        |  53.0 | 74.67 |\n","|       painting      | 69.57 | 82.32 |\n","|         sofa        | 59.19 | 70.37 |\n","|        shelf        | 41.22 | 58.07 |\n","|        house        | 29.92 | 38.94 |\n","|         sea         | 45.81 | 71.08 |\n","|        mirror       | 60.18 | 68.42 |\n","|         rug         |  48.0 | 52.33 |\n","|        field        | 23.48 | 43.75 |\n","|       armchair      | 41.82 | 65.18 |\n","|         seat        | 62.32 | 79.91 |\n","|        fence        | 31.65 | 40.88 |\n","|         desk        | 43.82 | 68.19 |\n","|         rock        | 30.21 | 45.98 |\n","|       wardrobe      | 36.38 | 58.01 |\n","|         lamp        | 59.27 | 72.42 |\n","|       bathtub       | 75.57 | 85.99 |\n","|       railing       | 30.02 | 39.51 |\n","|       cushion       | 52.95 | 67.36 |\n","|         base        | 34.32 | 56.95 |\n","|         box         | 17.49 | 22.64 |\n","|        column       | 43.09 | 55.98 |\n","|      signboard      |  32.5 | 42.14 |\n","|   chest of drawers  | 38.98 | 71.11 |\n","|       counter       | 15.56 | 17.55 |\n","|         sand        | 32.45 |  43.3 |\n","|         sink        | 67.13 | 73.37 |\n","|      skyscraper     | 46.48 | 62.22 |\n","|      fireplace      | 64.86 | 85.68 |\n","|     refrigerator    | 71.26 | 81.28 |\n","|      grandstand     |  42.7 | 79.93 |\n","|         path        | 20.71 | 34.36 |\n","|        stairs       | 27.85 | 36.95 |\n","|        runway       | 63.57 | 83.79 |\n","|         case        | 54.33 | 72.81 |\n","|      pool table     | 85.73 | 96.22 |\n","|        pillow       | 47.21 | 54.87 |\n","|     screen door     | 49.08 | 61.98 |\n","|       stairway      | 29.41 | 34.99 |\n","|        river        | 12.37 | 28.25 |\n","|        bridge       | 61.17 | 75.39 |\n","|       bookcase      | 31.78 | 44.82 |\n","|        blind        |  41.6 | 57.65 |\n","|     coffee table    | 54.58 | 74.89 |\n","|        toilet       | 67.36 | 90.92 |\n","|        flower       |  32.6 | 42.27 |\n","|         book        | 43.52 | 63.92 |\n","|         hill        |  5.33 |  7.25 |\n","|        bench        | 34.99 |  46.8 |\n","|      countertop     | 50.01 | 67.07 |\n","|        stove        | 72.73 | 78.98 |\n","|         palm        | 45.39 | 65.25 |\n","|    kitchen island   | 34.91 |  78.2 |\n","|       computer      |  53.0 | 64.61 |\n","|     swivel chair    | 44.12 | 57.45 |\n","|         boat        | 41.45 | 56.29 |\n","|         bar         |  29.6 | 42.35 |\n","|    arcade machine   | 39.49 | 44.16 |\n","|        hovel        |  5.99 |  8.15 |\n","|         bus         | 79.96 | 95.01 |\n","|        towel        | 53.26 | 59.32 |\n","|        light        | 47.24 |  54.1 |\n","|        truck        |  26.6 | 41.17 |\n","|        tower        |  26.6 | 42.24 |\n","|      chandelier     | 62.96 | 78.58 |\n","|        awning       | 16.82 | 18.65 |\n","|     streetlight     | 20.97 | 26.57 |\n","|        booth        |  24.3 | 37.41 |\n","| television receiver | 65.76 | 73.43 |\n","|       airplane      | 48.22 |  69.7 |\n","|      dirt track     |  2.65 | 20.33 |\n","|       apparel       | 28.94 | 41.25 |\n","|         pole        |  22.7 | 30.24 |\n","|         land        |  0.18 |  0.24 |\n","|      bannister      |  2.07 |  2.48 |\n","|      escalator      | 21.99 | 23.03 |\n","|       ottoman       | 44.95 | 59.12 |\n","|        bottle       | 11.66 | 15.14 |\n","|        buffet       |  46.2 | 54.82 |\n","|        poster       | 22.93 | 27.82 |\n","|        stage        | 11.18 | 21.58 |\n","|         van         | 43.45 | 56.93 |\n","|         ship        | 74.17 | 93.69 |\n","|       fountain      | 16.77 | 21.14 |\n","|    conveyer belt    |  38.9 | 73.89 |\n","|        canopy       | 22.75 | 29.85 |\n","|        washer       | 60.13 | 72.13 |\n","|      plaything      | 20.11 | 30.97 |\n","|    swimming pool    | 37.73 | 38.95 |\n","|        stool        | 33.74 | 55.46 |\n","|        barrel       | 32.25 | 66.94 |\n","|        basket       | 31.73 | 37.65 |\n","|      waterfall      | 27.15 | 52.52 |\n","|         tent        | 68.97 | 97.27 |\n","|         bag         |  7.02 |  8.91 |\n","|       minibike      |  67.6 | 76.41 |\n","|        cradle       | 71.51 | 96.23 |\n","|         oven        | 21.92 | 51.05 |\n","|         ball        | 31.85 |  49.8 |\n","|         food        | 45.69 | 57.86 |\n","|         step        |  0.06 |  0.06 |\n","|         tank        | 40.47 | 51.71 |\n","|      trade name     | 14.97 | 15.69 |\n","|      microwave      | 35.35 | 38.65 |\n","|         pot         | 39.15 | 46.67 |\n","|        animal       | 55.67 | 60.33 |\n","|       bicycle       | 52.02 |  66.7 |\n","|         lake        | 60.01 | 63.61 |\n","|      dishwasher     |  69.9 | 76.59 |\n","|        screen       | 58.25 | 72.62 |\n","|       blanket       |  6.12 |  7.64 |\n","|      sculpture      |  37.7 | 43.46 |\n","|         hood        | 52.47 | 54.97 |\n","|        sconce       | 32.64 | 36.46 |\n","|         vase        | 30.53 | 45.16 |\n","|    traffic light    | 25.76 | 39.28 |\n","|         tray        |  4.84 |  7.92 |\n","|        ashcan       | 34.63 | 47.42 |\n","|         fan         | 48.19 | 53.51 |\n","|         pier        | 19.96 | 25.85 |\n","|      crt screen     |  5.94 | 16.65 |\n","|        plate        | 45.17 |  61.3 |\n","|       monitor       | 10.76 | 11.74 |\n","|    bulletin board   | 42.15 | 53.57 |\n","|        shower       |  0.0  |  0.0  |\n","|       radiator      | 48.93 | 58.73 |\n","|        glass        | 12.18 | 13.21 |\n","|        clock        | 22.53 | 25.34 |\n","|         flag        |  44.0 | 51.34 |\n","+---------------------+-------+-------+\n","2022-08-16 13:08:47,511 - mmseg - INFO - Summary:\n","2022-08-16 13:08:47,515 - mmseg - INFO - \n","+-------+-------+-------+\n","|  aAcc |  mIoU |  mAcc |\n","+-------+-------+-------+\n","| 79.64 | 42.25 | 54.54 |\n","+-------+-------+-------+\n","2022-08-16 13:08:47,520 - mmseg - INFO - Iter(val) [2000]\taAcc: 0.7964, mIoU: 0.4225, mAcc: 0.5454, IoU.wall: 0.7382, IoU.building: 0.7912, IoU.sky: 0.9249, IoU.floor: 0.7702, IoU.tree: 0.7045, IoU.ceiling: 0.7977, IoU.road: 0.7952, IoU.bed : 0.8362, IoU.windowpane: 0.5668, IoU.grass: 0.6013, IoU.cabinet: 0.5465, IoU.sidewalk: 0.6109, IoU.person: 0.7615, IoU.earth: 0.2720, IoU.door: 0.4451, IoU.table: 0.5430, IoU.mountain: 0.4654, IoU.plant: 0.5112, IoU.curtain: 0.6433, IoU.chair: 0.5159, IoU.car: 0.8016, IoU.water: 0.5300, IoU.painting: 0.6957, IoU.sofa: 0.5919, IoU.shelf: 0.4122, IoU.house: 0.2992, IoU.sea: 0.4581, IoU.mirror: 0.6018, IoU.rug: 0.4800, IoU.field: 0.2348, IoU.armchair: 0.4182, IoU.seat: 0.6232, IoU.fence: 0.3165, IoU.desk: 0.4382, IoU.rock: 0.3021, IoU.wardrobe: 0.3638, IoU.lamp: 0.5927, IoU.bathtub: 0.7557, IoU.railing: 0.3002, IoU.cushion: 0.5295, IoU.base: 0.3432, IoU.box: 0.1749, IoU.column: 0.4309, IoU.signboard: 0.3250, IoU.chest of drawers: 0.3898, IoU.counter: 0.1556, IoU.sand: 0.3245, IoU.sink: 0.6713, IoU.skyscraper: 0.4648, IoU.fireplace: 0.6486, IoU.refrigerator: 0.7126, IoU.grandstand: 0.4270, IoU.path: 0.2071, IoU.stairs: 0.2785, IoU.runway: 0.6357, IoU.case: 0.5433, IoU.pool table: 0.8573, IoU.pillow: 0.4721, IoU.screen door: 0.4908, IoU.stairway: 0.2941, IoU.river: 0.1237, IoU.bridge: 0.6117, IoU.bookcase: 0.3178, IoU.blind: 0.4160, IoU.coffee table: 0.5458, IoU.toilet: 0.6736, IoU.flower: 0.3260, IoU.book: 0.4352, IoU.hill: 0.0533, IoU.bench: 0.3499, IoU.countertop: 0.5001, IoU.stove: 0.7273, IoU.palm: 0.4539, IoU.kitchen island: 0.3491, IoU.computer: 0.5300, IoU.swivel chair: 0.4412, IoU.boat: 0.4145, IoU.bar: 0.2960, IoU.arcade machine: 0.3949, IoU.hovel: 0.0599, IoU.bus: 0.7996, IoU.towel: 0.5326, IoU.light: 0.4724, IoU.truck: 0.2660, IoU.tower: 0.2660, IoU.chandelier: 0.6296, IoU.awning: 0.1682, IoU.streetlight: 0.2097, IoU.booth: 0.2430, IoU.television receiver: 0.6576, IoU.airplane: 0.4822, IoU.dirt track: 0.0265, IoU.apparel: 0.2894, IoU.pole: 0.2270, IoU.land: 0.0018, IoU.bannister: 0.0207, IoU.escalator: 0.2199, IoU.ottoman: 0.4495, IoU.bottle: 0.1166, IoU.buffet: 0.4620, IoU.poster: 0.2293, IoU.stage: 0.1118, IoU.van: 0.4345, IoU.ship: 0.7417, IoU.fountain: 0.1677, IoU.conveyer belt: 0.3890, IoU.canopy: 0.2275, IoU.washer: 0.6013, IoU.plaything: 0.2011, IoU.swimming pool: 0.3773, IoU.stool: 0.3374, IoU.barrel: 0.3225, IoU.basket: 0.3173, IoU.waterfall: 0.2715, IoU.tent: 0.6897, IoU.bag: 0.0702, IoU.minibike: 0.6760, IoU.cradle: 0.7151, IoU.oven: 0.2192, IoU.ball: 0.3185, IoU.food: 0.4569, IoU.step: 0.0006, IoU.tank: 0.4047, IoU.trade name: 0.1497, IoU.microwave: 0.3535, IoU.pot: 0.3915, IoU.animal: 0.5567, IoU.bicycle: 0.5202, IoU.lake: 0.6001, IoU.dishwasher: 0.6990, IoU.screen: 0.5825, IoU.blanket: 0.0612, IoU.sculpture: 0.3770, IoU.hood: 0.5247, IoU.sconce: 0.3264, IoU.vase: 0.3053, IoU.traffic light: 0.2576, IoU.tray: 0.0484, IoU.ashcan: 0.3463, IoU.fan: 0.4819, IoU.pier: 0.1996, IoU.crt screen: 0.0594, IoU.plate: 0.4517, IoU.monitor: 0.1076, IoU.bulletin board: 0.4215, IoU.shower: 0.0000, IoU.radiator: 0.4893, IoU.glass: 0.1218, IoU.clock: 0.2253, IoU.flag: 0.4400, Acc.wall: 0.8708, Acc.building: 0.9129, Acc.sky: 0.9582, Acc.floor: 0.8746, Acc.tree: 0.8590, Acc.ceiling: 0.8916, Acc.road: 0.8649, Acc.bed : 0.9609, Acc.windowpane: 0.7037, Acc.grass: 0.8095, Acc.cabinet: 0.6793, Acc.sidewalk: 0.7509, Acc.person: 0.8752, Acc.earth: 0.3765, Acc.door: 0.5913, Acc.table: 0.6959, Acc.mountain: 0.6250, Acc.plant: 0.6411, Acc.curtain: 0.8075, Acc.chair: 0.6597, Acc.car: 0.8779, Acc.water: 0.7467, Acc.painting: 0.8232, Acc.sofa: 0.7037, Acc.shelf: 0.5807, Acc.house: 0.3894, Acc.sea: 0.7108, Acc.mirror: 0.6842, Acc.rug: 0.5233, Acc.field: 0.4375, Acc.armchair: 0.6518, Acc.seat: 0.7991, Acc.fence: 0.4088, Acc.desk: 0.6819, Acc.rock: 0.4598, Acc.wardrobe: 0.5801, Acc.lamp: 0.7242, Acc.bathtub: 0.8599, Acc.railing: 0.3951, Acc.cushion: 0.6736, Acc.base: 0.5695, Acc.box: 0.2264, Acc.column: 0.5598, Acc.signboard: 0.4214, Acc.chest of drawers: 0.7111, Acc.counter: 0.1755, Acc.sand: 0.4330, Acc.sink: 0.7337, Acc.skyscraper: 0.6222, Acc.fireplace: 0.8568, Acc.refrigerator: 0.8128, Acc.grandstand: 0.7993, Acc.path: 0.3436, Acc.stairs: 0.3695, Acc.runway: 0.8379, Acc.case: 0.7281, Acc.pool table: 0.9622, Acc.pillow: 0.5487, Acc.screen door: 0.6198, Acc.stairway: 0.3499, Acc.river: 0.2825, Acc.bridge: 0.7539, Acc.bookcase: 0.4482, Acc.blind: 0.5765, Acc.coffee table: 0.7489, Acc.toilet: 0.9092, Acc.flower: 0.4227, Acc.book: 0.6392, Acc.hill: 0.0725, Acc.bench: 0.4680, Acc.countertop: 0.6707, Acc.stove: 0.7898, Acc.palm: 0.6525, Acc.kitchen island: 0.7820, Acc.computer: 0.6461, Acc.swivel chair: 0.5745, Acc.boat: 0.5629, Acc.bar: 0.4235, Acc.arcade machine: 0.4416, Acc.hovel: 0.0815, Acc.bus: 0.9501, Acc.towel: 0.5932, Acc.light: 0.5410, Acc.truck: 0.4117, Acc.tower: 0.4224, Acc.chandelier: 0.7858, Acc.awning: 0.1865, Acc.streetlight: 0.2657, Acc.booth: 0.3741, Acc.television receiver: 0.7343, Acc.airplane: 0.6970, Acc.dirt track: 0.2033, Acc.apparel: 0.4125, Acc.pole: 0.3024, Acc.land: 0.0024, Acc.bannister: 0.0248, Acc.escalator: 0.2303, Acc.ottoman: 0.5912, Acc.bottle: 0.1514, Acc.buffet: 0.5482, Acc.poster: 0.2782, Acc.stage: 0.2158, Acc.van: 0.5693, Acc.ship: 0.9369, Acc.fountain: 0.2114, Acc.conveyer belt: 0.7389, Acc.canopy: 0.2985, Acc.washer: 0.7213, Acc.plaything: 0.3097, Acc.swimming pool: 0.3895, Acc.stool: 0.5546, Acc.barrel: 0.6694, Acc.basket: 0.3765, Acc.waterfall: 0.5252, Acc.tent: 0.9727, Acc.bag: 0.0891, Acc.minibike: 0.7641, Acc.cradle: 0.9623, Acc.oven: 0.5105, Acc.ball: 0.4980, Acc.food: 0.5786, Acc.step: 0.0006, Acc.tank: 0.5171, Acc.trade name: 0.1569, Acc.microwave: 0.3865, Acc.pot: 0.4667, Acc.animal: 0.6033, Acc.bicycle: 0.6670, Acc.lake: 0.6361, Acc.dishwasher: 0.7659, Acc.screen: 0.7262, Acc.blanket: 0.0764, Acc.sculpture: 0.4346, Acc.hood: 0.5497, Acc.sconce: 0.3646, Acc.vase: 0.4516, Acc.traffic light: 0.3928, Acc.tray: 0.0792, Acc.ashcan: 0.4742, Acc.fan: 0.5351, Acc.pier: 0.2585, Acc.crt screen: 0.1665, Acc.plate: 0.6130, Acc.monitor: 0.1174, Acc.bulletin board: 0.5357, Acc.shower: 0.0000, Acc.radiator: 0.5873, Acc.glass: 0.1321, Acc.clock: 0.2534, Acc.flag: 0.5134\n"]}],"source":["from mmseg.datasets import build_dataset\n","from mmseg.models import build_segmentor\n","from mmseg.apis import train_segmentor\n","import mmcv\n","import os.path as osp\n","\n","\n","# Build the dataset\n","datasets = [build_dataset(cfg.data.train)]\n","\n","# Build the detector\n","model = build_segmentor(cfg.model)\n","\n","# Add an attribute for visualization convenience\n","model.CLASSES = datasets[0].CLASSES\n","\n","# Create work_dir\n","mmcv.mkdir_or_exist(osp.abspath(cfg.work_dir))\n","train_segmentor(model, datasets, cfg, distributed=False, validate=True, \n","                meta=dict())"]},{"cell_type":"code","execution_count":19,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"1VK6fo4V-V4ZynjmRL-Scvu_0fJrW2wk_"},"executionInfo":{"elapsed":32156,"status":"ok","timestamp":1660655394757,"user":{"displayName":"Yusuf Bilgen","userId":"05683862783259875968"},"user_tz":-180},"id":"rbZminD1AFM4","outputId":"1008da89-9042-43ff-a752-d80d4e2061f8"},"outputs":[],"source":["import matplotlib.pyplot as plt\n","from mmseg.core.evaluation import get_palette\n","model.cfg = cfg\n","#img = '/content/mmsegmentation/data/ade/ADEChallengeData2016/images/validation/ADE_val_00001000.jpg'\n","resimler=['validation/ADE_val_00001962.jpg' , 'validation/ADE_val_00001963.jpg' , 'validation/ADE_val_00001457.jpg' , \n","          'validation/ADE_val_00001458.jpg' , 'validation/ADE_val_00001459.jpg' , 'training/ADE_train_00000565.jpg' ,\n","          'training/ADE_train_00000936.jpg' , 'training/ADE_train_00000952.jpg' , 'training/ADE_train_00003194.jpg' , \n","          'training/ADE_train_00006845.jpg']\n","for img in resimler:\n","  result = inference_segmentor(model, '/content/mmsegmentation/data/ade/ADEChallengeData2016/images/'+img)\n","  show_result_pyplot(model, '/content/mmsegmentation/data/ade/ADEChallengeData2016/images/'+img, result,get_palette('ade20k'))"]},{"cell_type":"code","execution_count":18,"metadata":{"executionInfo":{"elapsed":24,"status":"ok","timestamp":1660655332208,"user":{"displayName":"Yusuf Bilgen","userId":"05683862783259875968"},"user_tz":-180},"id":"c1VlIY8zczub"},"outputs":[],"source":[""]}],"metadata":{"accelerator":"GPU","colab":{"authorship_tag":"ABX9TyPy/ctpJsjsCIm3x182PTcc","collapsed_sections":[],"name":"retraining_knet_deeplabv3_ade20k_image_segmentation.ipynb","version":""},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}